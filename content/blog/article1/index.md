---
title: "How We Used Karpenter to Slash Costs and Save Engineering Time"
date: 2025-09-10
draft: false
tags: ["Kubernetes", "Karpenter", "Cloud", "AWS", "DevOps", "Autoscaling", "EKS"]
categories: ["Kubernetes", "Cloud Native", "DevOps Tools"]
author: "Francisco Meza"
showHero: true
description: "A real-world case study of how we migrated from Cluster Autoscaler to Karpenter on EKS, saving 28% on costs while simplifying cluster scaling."
---

## ğŸš€ Introduction

When I first heard about **Karpenter**, I was skeptical.
Weâ€™d already invested time tuning the **Cluster Autoscaler**, had spot instances in place, and swapping out a core part of our infrastructure felt risky.

But then the AWS bill landed.

And a few too many Slack messages like:

> â€œWhy are we still scaling to r5.4xlarge for background jobs?â€

So, we decided to give Karpenter a shot â€” and the results were way better than we expected.

---

## The Problem

We run a moderately sized **EKS cluster** that handles both long-running services and bursty background jobs.
Even with autoscaling enabled, we kept running into familiar pain points:

- âŒ Inefficient instance types being selected
- ğŸŒ Slower pod scheduling during peak traffic
- ğŸ’¸ Over-provisioning due to rigid node group configurations
- âš ï¸ Spot instance churn causing workload disruptions

Managing scaling logic was becoming a **weekly chore**, and the nodes never quite matched the workload.

---

## Why Karpenter?

Karpenter is an open-source **Kubernetes autoscaler** built by AWS.
Unlike the Cluster Autoscaler, it **provisions nodes dynamically**, skipping predefined node groups entirely.

What stood out for us:

- âœ… Works directly with the Kubernetes scheduler
- âœ… Doesnâ€™t require Auto Scaling Groups or Launch Templates
- âœ… Supports smart instance selection (on-demand + spot)
- âœ… Scales nodes up/down within seconds

---

## What Changed

Within the **first week of rollout**, we saw real impact:

- ğŸ“‰ **28% lower EC2 costs** â€” mostly from smarter spot instance usage
- âš¡ **2x faster pod scheduling** during bursts
- ğŸ› ï¸ **Less ops overhead** â€” no more tweaking node group configs
- ğŸ™‚ **Happier developers** â€” fewer complaints about pods stuck in `Pending`

Karpenter was launching just the right instance types, with just enough resources.
No more overkill, no more lag.

---

## What We Learned

- ğŸ”„ Karpenter **skips node groups entirely** â€” no ASGs or launch templates needed
- ğŸ¯ Instance selection is **dynamic** and workload-driven
- ğŸš¦ Multiple provisioners help isolate **spot vs. on-demand** workloads
- ğŸ‘€ You still need to **monitor evictions** and spot availability by region

For bursty jobs or unpredictable traffic, Karpenter really shines.

---

## Would I Recommend It?

**Yes â€” 100%.**

If youâ€™re running on EKS and still using Cluster Autoscaler, Karpenter is worth trying.
Itâ€™s not a magic bullet, but it gave us meaningful cost savings and freed up engineering time.

The cost savings were nice, but the **time saved by our team** was the real win.

---

## Further Reading

- [Karpenter Documentation](https://karpenter.sh/)
- [GitHub: Karpenter](https://github.com/aws/karpenter)
- [EKS Best Practices Guide](https://aws.github.io/aws-eks-best-practices/)
